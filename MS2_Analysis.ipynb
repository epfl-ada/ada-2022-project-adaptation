{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2af5202-cd4d-4fe2-9e7e-48869ec70229",
   "metadata": {},
   "source": [
    "# Part 0: Initialising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b347be5c-381b-4203-a676-ae35909a42cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing\n",
    "import matplotlib.font_manager as font_manager\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib as mpl\n",
    "import matplotlib.ticker as mtick\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "from scipy.stats import bootstrap\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import requests\n",
    "\n",
    "params = {\n",
    "    \"axes.titlesize\": 14,\n",
    "    \"axes.labelsize\": 12,\n",
    "    \"font.size\": 12,\n",
    "    \"legend.fontsize\": 12,\n",
    "    \"xtick.labelsize\": 12,\n",
    "    \"ytick.labelsize\": 12,\n",
    "    \"text.usetex\": False,\n",
    "}\n",
    "\n",
    "mpl.rcParams.update(params)\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4e5555-b4fc-4cd9-acea-f54ff5aef1ad",
   "metadata": {},
   "source": [
    "To start with, we import three datasets that are available on YouNiverse:\n",
    "\n",
    "``df_timeseries_en.tsv.gz``  \n",
    "``df_channels_en.tsv.gz``  \n",
    "``yt_metadata_helper.feather``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c93da3e-46e0-4e9b-98dc-c725a9d981fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_series = pd.read_csv(\n",
    "    \"./data/df_timeseries_en.tsv.gz\", compression=\"infer\", sep=\"\\t\"\n",
    ")\n",
    "df_time_series[\"datetime\"] = pd.to_datetime(df_time_series[\"datetime\"])\n",
    "# round the total number of subscribers, it is easier to consider 1 person and instead half of a person...\n",
    "df_time_series.subs = df_time_series.subs.round(0)\n",
    "\n",
    "df_channels = pd.read_csv(\"./data/df_channels_en.tsv.gz\", compression=\"infer\", sep=\"\\t\")\n",
    "df_channels[\"join_date\"] = pd.to_datetime(df_channels[\"join_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb8de83-f104-4db7-a03d-45eedff3600d",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_metadatas = pd.read_feather(\n",
    "    \"./data/yt_metadata_helper.feather\",\n",
    "    columns=[\n",
    "        \"categories\",\n",
    "        \"upload_date\",\n",
    "        \"duration\",\n",
    "        \"like_count\",\n",
    "        \"dislike_count\",\n",
    "        \"view_count\",\n",
    "        \"channel_id\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970f1b94-0e05-4c45-affe-704a9e7daf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_series.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885c9ac7-9adf-4040-a221-a0bd3d445cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_channels.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a8cc75-ff4d-49f8-a7f7-4fd6b6600385",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_metadatas.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c191d301",
   "metadata": {},
   "source": [
    "We will also import a dataset that is created by us, called `titles_metadata`, which contains the titles and the categories of each video. For Milestone three, we will generate the same metadata for titles, but including the display ID for matching the titles with videos. For the purpose of Milestone 2, we will continue with the current `titles_metadata` for initial analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dc9dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_metadata = pd.read_feather(\n",
    "    \"./data/yt_metadata_title_helper.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5919e3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b3e231-0688-4f96-bf22-90ab5e8389ab",
   "metadata": {},
   "source": [
    "# Part 1: Initial Analysis and Data Visualization\n",
    "\n",
    "In this section, we analyze the YouNiverse data to determine the potential factors that could lead to success on Youtube. This initial analysis will help us narrow down a subset of the dataset to focus on for our Milestone 3 analysis.\n",
    "\n",
    "## Question 1: How is the weekly content creation pattern of Youtubers regarding the upload frequency, video lengths, upload time?\n",
    "\n",
    "### Section 1: Video Upload Frequency\n",
    "\n",
    "In this section, we mainly consider the weekly video upload frequency. To do that, we first group the `video_metadatas` by upload week for all channels, to have an idea on the upload trends. We do not use `df_time_series` for the purpose of this section, which has ready-to-use weekly information regarding each channel, as it only considers the data from 2015-01-05 to 2019-10-06."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a178f754-ff2e-4d27-86f4-a92db2511de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_count = (\n",
    "    video_metadatas.groupby(pd.Grouper(key=\"upload_date\", freq=\"W\")).count().channel_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f4c9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(2005, 2021):\n",
    "    total_videos_year = video_count[video_count.index.year.isin([year])].sum()\n",
    "    print(\"We have {:_} video in {}\".format(total_videos_year, year))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84a06f8",
   "metadata": {},
   "source": [
    "This data shows that we have to be careful with the different timing within each dataframe used. As we will see later on, there are sharp decreases in the data over time, depending on how many videos were crawled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c9e4a5-8d26-45e5-855e-19b2199b229f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(video_count, color=\"#7570b3\", ls=\"--\", label=\"\\% videos uploaded\")\n",
    "plt.yscale(\"log\")\n",
    "plt.ylabel(\"Number of Videos\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.title(\"Number of videos uploaded each week\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82de2c2-6451-4d1d-a070-11dccbb95d4f",
   "metadata": {},
   "source": [
    "From the graph above, we can see that the number of videos being uploaded to YouTube has increased steadily since 2005. We want to have a closer look at the number of videos uploaded by each channel to understand how many videos it takes in order to be successfull. For this preliminary analysis, we only consider the number of videos uploaded by each channel per year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f7372e-9087-4202-9573-fb6ae7a787df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following graph shows how many videos each channel uploads to YouTube per year.\n",
    "video_metadatas[\"yearNumber\"] = video_metadatas[\"upload_date\"].dt.year\n",
    "vd_cnt_by_id_yr = (\n",
    "    video_metadatas.groupby([\"channel_id\", \"yearNumber\"])\n",
    "    .count()\n",
    "    .categories.unstack()\n",
    "    .reset_index()\n",
    ")\n",
    "vd_cnt_by_id_yr.columns.name = None\n",
    "vd_cnt_by_id_yr_summary = vd_cnt_by_id_yr.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c392d276-ef9a-4099-8df5-548c8cc15ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.fill_between(\n",
    "    x=list(vd_cnt_by_id_yr_summary.columns.values),\n",
    "    y1=list(vd_cnt_by_id_yr_summary.loc[\"25%\", :]),\n",
    "    y2=list(vd_cnt_by_id_yr_summary.loc[\"75%\", :]),\n",
    "    alpha=0.5,\n",
    "    color=\"gray\",\n",
    ")\n",
    "plt.plot(vd_cnt_by_id_yr_summary.loc[\"50%\", :], color=\"black\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Yearly Upload Frequency\")\n",
    "plt.title(\"The 2nd and 3rd quartiles of yearly video upload frequency\")\n",
    "# here we choose quartiles, since the mean would be significantly affected by extremely high yearly upload rates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42db581f-04bf-4093-8c90-223d8f57b3d5",
   "metadata": {},
   "source": [
    "This graphs shows that YouTubers upload more videos every year with time, and the variation of upload frequency between channels also increased significantly since the beginning of the study period."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d4cfb5-d4c3-44fd-b807-61652dd7b139",
   "metadata": {},
   "source": [
    "### Section 2: Video Lengths\n",
    "\n",
    "Firstly, we will take a look at the basic statistics of video lengths using `video_metadatas` . To make it easier to understand, we first convert the duration into minutes for the subsequent analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1c73d9-4058-4796-be4d-91a0df613880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide the video duration by 60 to convert duration to minutes\n",
    "video_metadatas[\"duration_min\"] = video_metadatas[\"duration\"] / 60\n",
    "video_metadatas.duration_min.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc875406-407a-4199-92e6-a0285e1d0526",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_min_cumul = plt.hist(\n",
    "    video_metadatas.duration_min, bins=100, log=True, cumulative=-1, histtype=\"step\"\n",
    ")\n",
    "plt.title(\"Histogram of Duration for YouTube Videos (cumulative)\")\n",
    "plt.ylabel(\"# of Videos (in log scale)\")\n",
    "plt.xlabel(\"Duration in Minutes\")\n",
    "plt.xticks(rotation=30, ha=\"right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eddf678-64a2-4271-aaa6-c3ecc37fc021",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.loglog(duration_min_cumul[1][1:], duration_min_cumul[0])\n",
    "plt.title(\"Histogram of Duration for YouTube Videos (cumulative)\")\n",
    "plt.ylabel(\"# of Videos (in log scale)\")\n",
    "plt.xlabel(\"Duration\")\n",
    "plt.xticks(rotation=30, ha=\"right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232a9f59-f9ae-4b05-9ced-1c07802ea518",
   "metadata": {},
   "source": [
    "From the basic statistical information and the histogram, we can observe a significant difference between the mean (12.63 minutes) and the median (4.73 minutes). Furthermore, the maximum duration (100 hours) is much higher compared to both, the median and the mean. The distribution of the duration resembles that of a heavy tail distribution. This observation suggests that there are extremely long videos in the dataset that would increase the mean significantly. Therefore, a visualization with quartiles serves as a less distorted representation of the dataset as it does not consider outliers.\n",
    "\n",
    "Therefore, we will have a look at the quartiles of duration of videos in the dataset to have a better idea about the distribution: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9feec452-8f43-4c65-a91a-e27fa4477b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(video_metadatas[\"duration_min\"], showfliers=False, vert=False)\n",
    "plt.title(\"Duration of Videos in Minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea832414-588e-4423-b464-647ce0c5ae39",
   "metadata": {},
   "source": [
    "Here, we see that throughout the study period, most of the videos are between zero and 25 minutes long. To investigate whether the variation of video length is also varying with time, we take a look at the evolution of this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f384aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vd_duration_by_id_yr = (\n",
    "    video_metadatas.groupby([\"channel_id\", \"yearNumber\"])[\"duration_min\"]\n",
    "    .mean()\n",
    "    .unstack()\n",
    "    .reset_index()\n",
    ")\n",
    "vd_duration_by_id_yr.columns.name = None\n",
    "vd_duration_by_id_yr_summary = vd_duration_by_id_yr.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3638dcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.fill_between(\n",
    "    x=list(vd_duration_by_id_yr_summary.columns.values),\n",
    "    y1=list(vd_duration_by_id_yr_summary.loc[\"25%\", :]),\n",
    "    y2=list(vd_duration_by_id_yr_summary.loc[\"75%\", :]),\n",
    "    alpha=0.5,\n",
    "    color=\"gray\",\n",
    ")\n",
    "plt.plot(vd_duration_by_id_yr_summary.loc[\"50%\", :], color=\"black\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Average Video Duration for Each Channel\")\n",
    "plt.title(\"The 2nd and 3rd quartiles of average yearly video duration\")\n",
    "# here we choose quartiles, since the mean would be significantly affected by extremely high yearly upload rates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62915d3",
   "metadata": {},
   "source": [
    "From this graph, it is obvious that the variance of mean video duration for each channel is increasing with time, and the median itself is also increasing with time. This means that comparing to the beginning of study period, channels increased the video duration, and there are more channels with vastly different video duration towards the end of the study period."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3312f3f-980c-4460-a60d-b587927dc576",
   "metadata": {},
   "source": [
    "### Section 3: Upload Time\n",
    "In this section, we want to investigate at what points during the week YouTubers upload their videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12d27ec-0065-4130-be2a-6a57ac6aa3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_metadatas[\"weekNumber\"] = video_metadatas[\"upload_date\"].dt.weekday\n",
    "vd_cnt_by_id_wk = (\n",
    "    video_metadatas.groupby([\"channel_id\", \"weekNumber\", \"yearNumber\"])\n",
    "    .count()\n",
    "    .categories.unstack()\n",
    "    .reset_index()\n",
    ")\n",
    "vd_cnt_by_id_wk.columns.name = None\n",
    "vd_cnt_by_id_wk[\"mean_upload\"] = vd_cnt_by_id_wk.iloc[:, 2:].mean(axis=1, skipna=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12107ba-808c-46c3-a84a-79d6c30503d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"MON\", \"TUE\", \"WED\", \"THU\", \"FRI\", \"SAT\", \"SUN\"]\n",
    "ax = sns.boxplot(\n",
    "    x=\"weekNumber\", y=\"mean_upload\", data=vd_cnt_by_id_wk, showfliers=False\n",
    ").set(xlabel=\"Week Days\", ylabel=\"Mean Upload\", xticklabels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6c9474-6628-4cb6-9c29-57290d54f692",
   "metadata": {},
   "source": [
    "This boxplot shows that the variation between upload rate during weekdays are not significantly different. However, during the weekend, it seems that mean upload rate is less than during the week. In the next step, we visualize it better by counting the total number of videos uploaded each day of the week, regardless of the channel ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c682e02f-4bb5-4a74-b6e3-6221a52c9bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vd_cnt_by_wk = (\n",
    "    video_metadatas.groupby([\"weekNumber\", \"yearNumber\"])\n",
    "    .count()\n",
    "    .categories.unstack()\n",
    "    .reset_index()\n",
    ")\n",
    "vd_cnt_by_wk.columns.name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35a9f95-6989-4ae6-ae56-20dbd856e679",
   "metadata": {},
   "outputs": [],
   "source": [
    "vd_cnt_by_wk_norm = vd_cnt_by_wk.iloc[:, 2:] / vd_cnt_by_wk.iloc[:, 2:].sum(skipna=True)\n",
    "plt.rcParams[\"figure.figsize\"] = (15, 10)\n",
    "plt.plot(vd_cnt_by_wk_norm.T)\n",
    "plt.legend(\n",
    "    [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    ")\n",
    "plt.xlabel(\"year\")\n",
    "plt.ylabel(\"NORMALISED: video uploaded each weekday\")\n",
    "plt.title(\"NORMALISED: The evolution of video upload rate for each weekday\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82aed595-2907-431f-be7c-bcf61f4c582c",
   "metadata": {},
   "source": [
    "This graph suggests that the number of videos uploaded from Monday to Friday is not significantly different from each other throughout the study period. Generally speaking, YouTubers upload more during weekdays than during the weekends. However, we can also observe an increasing number of videos uploaded on Saturdays in more recent years."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ce46f7-27b4-42c1-b5a5-1ef56b569337",
   "metadata": {},
   "source": [
    "## Question 2: How are the subscription patterns for reaching key numbers of subscribers, aka, 1k, 10k, 100k, 1M?\n",
    "\n",
    "In this section, we investigate the time frame for YouTubers to reach key milestones in their channel success - number of subscriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3340c8-074a-41f7-967b-2b745a618d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_channel_ascension(start_subs, end_subs):\n",
    "    \"\"\"finds the channels in the time series that have less than the start_subs and more than end_subs.\n",
    "    It means that it begins with less than start_subs and have now at least end_subs\n",
    "\n",
    "    Args:\n",
    "        start_subs (float): low_threshold\n",
    "        end_subs (float): high_threshold\n",
    "\n",
    "    Returns:\n",
    "        dataframe containing all the channels with evolution from starts_subs to end_subs\n",
    "    \"\"\"\n",
    "    under_start_subs = df_time_series[df_time_series[\"subs\"] < start_subs]\n",
    "    more_end_subs = df_time_series[df_time_series[\"subs\"] > end_subs]\n",
    "    channel_start_to_end = df_time_series[\n",
    "        df_time_series.channel.isin(under_start_subs.channel)\n",
    "        & df_time_series.channel.isin(more_end_subs.channel)\n",
    "    ]\n",
    "    return channel_start_to_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab24d2e-8ed5-4407-ba1a-587061d52dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_time_to_reach_X_subs(df, lower_bound, upper_bound):\n",
    "    time_to_reach_X_subs = df.groupby(\"channel\").apply(\n",
    "        lambda group: pd.Series(\n",
    "            {\n",
    "                \"from_zero_to_hero_duration\": group[group.subs > upper_bound][\n",
    "                    \"datetime\"\n",
    "                ].iloc[0]\n",
    "                - group[group.subs < lower_bound][\"datetime\"].iloc[-1]\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "    return time_to_reach_X_subs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cacc53-9aee-4bf1-908e-45f5c011d5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_10K_to_1M = get_df_channel_ascension(10_000, 1_000_000)\n",
    "print(\n",
    "    \"We have {} channels that begins with at most 10K subs and reach at least 1M\".format(\n",
    "        channel_10K_to_1M.channel.nunique()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec912070",
   "metadata": {},
   "source": [
    "Example of a channel to implement the function defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e618fbfd-56b5-4d59-b133-ccfacd46d455",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_channel = channel_10K_to_1M.iloc[0]\n",
    "test = channel_10K_to_1M[channel_10K_to_1M[\"channel\"] == first_channel.channel]\n",
    "# test = test[(test['datetime'] > np.datetime64('2018-07-20')) & (test['datetime'] < np.datetime64('2019-01-20'))]\n",
    "test.plot(x=\"datetime\", y=\"subs\")\n",
    "print(\"There are {} weeks for this channel\".format(test.shape[0]))\n",
    "\n",
    "# just check that the first dimension of the test df (it gives the nb of weeks) multiplied\n",
    "# by 7 (it gives the total nb of days) is equal to the last date - first date. If yes, then we have a continuous\n",
    "# chronology\n",
    "print(\n",
    "    \"We should have approximately the same value : \\n{} and {}\".format(\n",
    "        7 * test.shape[0], test.iloc[-1].datetime - test.iloc[0].datetime\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f5fcfe-f363-4146-8ac4-36b111180e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the time it takes to go from less than 10K to 1M\n",
    "time_to_reach_1M = get_mean_time_to_reach_X_subs(channel_10K_to_1M, 10_000, 1_000_000)\n",
    "time_to_reach_1M.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f43d08f-1c45-4945-9910-93ca62e9e670",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"In average YTbers take {} days to reach 1M of subscribers\".format(\n",
    "        time_to_reach_1M[\"from_zero_to_hero_duration\"].mean().days\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c5e96f-5187-4b0e-9539-0fcc7df016f2",
   "metadata": {},
   "source": [
    "We will then bootstrap this result for Milestone 3 to see the time it takes to reach 1M subscribers and its confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f29dd8-2445-451b-93e0-101733c4391b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = time_to_reach_1M[\"from_zero_to_hero_duration\"].apply(\n",
    "    lambda delta_time: delta_time.days\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb5e9df-faff-4f84-bded-fd710e4794c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng()\n",
    "conf_interval_reach_1M = bootstrap(\n",
    "    (data,),\n",
    "    np.mean,\n",
    "    confidence_level=0.95,\n",
    "    random_state=rng,\n",
    ").confidence_interval\n",
    "conf_interval_reach_1M\n",
    "\n",
    "print(\n",
    "    \"The 95% interval of confidence, the time taken to reach 1M (from 10K) is [{}, {}]\".format(\n",
    "        conf_interval_reach_1M.low, conf_interval_reach_1M.high\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a5be8a-c59d-44ff-83f7-96fe718ed1a2",
   "metadata": {},
   "source": [
    "## Question 3: Which categories are more popular during the study period? Which types of videos receive more positive feedback?\n",
    "\n",
    "In this question, we will use `video_metadatas` to determine which categories are more popular and have a high amount of views. This step helps in narrowing down our categories of interest to three categories that we want to investigate further for Milestone 3.\n",
    "\n",
    "### Section 1: Number of Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f544d210-6dc8-427c-bc46-054f6906312f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  make a copy of the video_metadatas\n",
    "videos_with_cat = video_metadatas[:]\n",
    "videos_with_cat[\"categories\"] = videos_with_cat[\"categories\"].apply(\n",
    "    lambda x: x.replace(\" & \", \"_\")\n",
    ")\n",
    "\n",
    "# delete the rows with empty categories\n",
    "videos_with_cat.categories.replace(\"\", np.nan, inplace=True)\n",
    "videos_with_cat.dropna(subset=[\"categories\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ea1aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average view counts for videos from each category across time\n",
    "mean_views = (\n",
    "    videos_with_cat.dropna(axis=0).groupby([\"categories\", \"yearNumber\"]).mean()\n",
    ")\n",
    "mean_views = mean_views.view_count.unstack().reset_index()\n",
    "mean_views.columns.name = None\n",
    "mean_views = mean_views.sort_values(\n",
    "    by=2019, ascending=False, ignore_index=True\n",
    ")\n",
    "\n",
    "print(mean_views.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffbf95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_COLORS = 15\n",
    "cm = plt.get_cmap('gist_rainbow')\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_prop_cycle(color=[cm(1.*videos_with_cat.categories.indexof(c)/NUM_COLORS) for c in mean_views.categories])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813ee0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary = [cm(1.*i/NUM_COLORS) for i in range(NUM_COLORS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d2964d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (15, 10)\n",
    "for i in np.arange(mean_views.shape[0]):\n",
    "    plt.plot(\n",
    "        mean_views.loc[\n",
    "            i,\n",
    "        ][2:],\n",
    "        label=mean_views.loc[i,][\n",
    "            0:1\n",
    "        ][0],\n",
    "    )\n",
    "plt.semilogy()    \n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xlabel(\"year\")\n",
    "plt.ylabel(\"mean video view count\")\n",
    "plt.title(\"mean video view counts per year for each category\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0116b7aa",
   "metadata": {},
   "source": [
    "The results of the data above is obtained by averaging the view counts of all videos in the same category by year. It shows that on average, Music and Comedy are the two top categories for view counts from 2005 to 2017. From 2018 to 2019, Film & Animation replaces Music on the top two spots. However, all top four categories are showing a decrease in their mean video view counts. However, there is not a genre of videos that shows obvious growth in mean video view counts over the study period, while most of the categories seem to stay more or less the same level, non-profit and news & politics categories seem to have obvious drop in their mean video view counts.\n",
    "\n",
    "Now let's investigate how popular are the videos from each category, and how the trend changes over time. For this purpose, we will now shift to the total video view counts, instead of the mean ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a3d4c6-f5dc-4760-b4f2-f910e4bce5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine how many videos are uploaded to YouTube by each channel by year\n",
    "video_count_by_year = (\n",
    "    videos_with_cat.dropna(axis=0).groupby([\"categories\", \"yearNumber\"]).sum()\n",
    ")\n",
    "video_view_count_by_year = video_count_by_year.view_count.unstack().reset_index()\n",
    "video_view_count_by_year.columns.name = None\n",
    "video_view_count_by_year = video_view_count_by_year.sort_values(\n",
    "    by=2019, ascending=False, ignore_index=True\n",
    ")\n",
    "# NOTE THAT CATEGORIES::MOVIES AND SHOWS HAVE VERY FEW DATA!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9d0286-8f29-418f-bde9-6f9ec3a1b9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (15, 10)\n",
    "for i in np.arange(video_view_count_by_year.shape[0]):\n",
    "    plt.plot(\n",
    "        video_view_count_by_year.loc[\n",
    "            i,\n",
    "        ][2:],\n",
    "        label=video_view_count_by_year.loc[i,][\n",
    "            0:1\n",
    "        ][0],\n",
    "    )\n",
    "plt.semilogy()    \n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.xlabel(\"year\")\n",
    "plt.ylabel(\"video view count\")\n",
    "plt.title(\"video view counts per year for each category\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60d57ab",
   "metadata": {},
   "source": [
    "From previous plot, we could see that by 2019, the top four categories with highest mean view counts are Comedy, Film & Animation, Music, Gaming, whereas People & Blogs was placed at the 7th. However, here we can observe that the total view counts for People & Blogs now enters the top four. This means that although that videos under People & Blogs have on average less views per video, there are probably a lot of videos under People & Blogs. Let's verify this observation by another plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3788f38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine how many videos are uploaded to YouTube by each channel by year\n",
    "upload_count_by_year = (\n",
    "    videos_with_cat.dropna(axis=0).groupby([\"categories\", \"yearNumber\"]).count()\n",
    ")\n",
    "upload_count_by_year = upload_count_by_year.view_count.unstack().reset_index()\n",
    "upload_count_by_year.columns.name = None\n",
    "upload_count_by_year = upload_count_by_year.sort_values(\n",
    "    by=2019, ascending=False, ignore_index=True\n",
    ")\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (15, 10)\n",
    "for i in np.arange(upload_count_by_year.shape[0]):\n",
    "    plt.plot(\n",
    "        upload_count_by_year.loc[\n",
    "            i,\n",
    "        ][2:],\n",
    "        label=upload_count_by_year.loc[i,][\n",
    "            0:1\n",
    "        ][0],\n",
    "    )\n",
    "plt.semilogy()    \n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.xlabel(\"year\")\n",
    "plt.ylabel(\"video upload count\")\n",
    "plt.title(\"upload counts per year for each category\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec235aae",
   "metadata": {},
   "source": [
    "Here we can observe that indeed there are more videos under people & Blogs category, compared to the other two categories with high mean view counts, Comedy and Film & Animation. This result suggests that the high total view counts can beat Comedy and Film & Animation probably because of its high number of videos uploaded.\n",
    "\n",
    "Lastly, we want to find out how are the video views distributed between different categories for each year. To do that, we will divide the total video counts per category per year by total video counts per year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0915aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMALISATION:\n",
    "## 1. view count - normalise wrt. total video views per year, to see which categories is viewed more every year\n",
    "plt.rcParams[\"figure.figsize\"] = (15, 10)\n",
    "for i in np.arange(video_view_count_by_year.shape[0]):\n",
    "    plt.plot(\n",
    "        video_view_count_by_year.loc[\n",
    "            i,\n",
    "        ][2:]\n",
    "        / video_view_count_by_year.sum(axis=0)[2:],\n",
    "        label=video_view_count_by_year.loc[i,][\n",
    "            0:1\n",
    "        ][0],\n",
    "    )\n",
    "plt.semilogy()  \n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.xlabel(\"year\")\n",
    "plt.ylabel(\"NORMALISED: video view count\")\n",
    "plt.title(\"NORMALISED: video view counts per year for each category\")\n",
    "plt.show()\n",
    "# view on music videos decreases, whereas on entertainment and gaming increases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dfb74a",
   "metadata": {},
   "source": [
    "The result indicates that the share of video counts across different categories are quite stable across the study period. However, it is also obvious that the view counts for Music is decreasing, and that for Entertainment, Gaiming and People & Blogs are somewhat increasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570ef40c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3fef307c",
   "metadata": {},
   "source": [
    "TO-DO: ADD NOTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f1df36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the time series dataframe to implement this, it would be easier. \n",
    "df_time_series['year'] = df_time_series.datetime.dt.year\n",
    "# penalize the big channel (many subs) by dividing the number of delta views by nb of total subscribers\n",
    "df_time_series['views_over_subs'] = df_time_series.delta_views / df_time_series.subs\n",
    "df_time_series.sample(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ddbc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_series[df_time_series.delta_views == 0].category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24acbc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "views_over_subs_per_year = (\n",
    "    df_time_series.groupby([\"category\", \"year\"]).sum()\n",
    ")\n",
    "views_over_subs_per_year.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c7f86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "views_over_subs_per_year = views_over_subs_per_year.views_over_subs.unstack().reset_index()\n",
    "views_over_subs_per_year.columns.name = None\n",
    "views_over_subs_per_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18b6c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_COLORS = 15\n",
    "cm = plt.get_cmap('gist_rainbow')\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_prop_cycle(color=[cm(1.*i/NUM_COLORS) for i in range(NUM_COLORS)])\n",
    "plt.rcParams[\"figure.figsize\"] = (15, 10)\n",
    "for i in np.arange(views_over_subs_per_year.shape[0]):\n",
    "    plt.plot(\n",
    "        views_over_subs_per_year.loc[\n",
    "            i,\n",
    "        ][2:],\n",
    "        label=views_over_subs_per_year.loc[i,][\n",
    "            0:1\n",
    "        ][0],\n",
    "    )\n",
    "    \n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xlabel(\"year\")\n",
    "plt.ylabel(\"video view count divided by number of subs\")\n",
    "plt.title(\"video view counts divided by nb of subs per year for each category\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6f40e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8705d803",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20df0e28-5a64-410c-a3fb-21764025b888",
   "metadata": {},
   "source": [
    "### Section 2: Number of Likes and Dislikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353bbd41-a97c-4228-8863-12b6e48d37c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_like_count_by_year = video_count_by_year.like_count.unstack().reset_index()\n",
    "video_like_count_by_year.columns.name = None\n",
    "video_like_count_by_year = video_like_count_by_year.sort_values(\n",
    "    by=2019, ascending=False, ignore_index=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714112c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_dislike_count_by_year = video_count_by_year.dislike_count.unstack().reset_index()\n",
    "video_dislike_count_by_year.columns.name = None\n",
    "video_dislike_count_by_year = video_dislike_count_by_year.sort_values(\n",
    "    by=2019, ascending=False, ignore_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba40afb-2f3d-476d-92bb-f3346f910849",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3. like count versus view count - normalise wrt. total like counts over view counts for each category for each year\n",
    "plt.rcParams[\"figure.figsize\"] = (15, 10)\n",
    "for i in np.arange(video_like_count_by_year.shape[0]):\n",
    "    plt.plot(\n",
    "        video_like_count_by_year.loc[\n",
    "            i,\n",
    "        ][2:]\n",
    "        / (video_view_count_by_year.loc[i][2:]),\n",
    "        label=video_like_count_by_year.loc[i,][\n",
    "            0:1\n",
    "        ][0],\n",
    "    )\n",
    "plt.semilogy()\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.xlabel(\"year\")\n",
    "plt.ylabel(\"NORMALISED: like over views\")\n",
    "plt.title(\"NORMALISED: video like counts over view counts per category per year\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5f3c40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e02c4a-2a91-482e-933c-a07eb1b325e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (15, 10)\n",
    "for i in np.arange(video_dislike_count_by_year.shape[0]):\n",
    "    plt.plot(\n",
    "        video_dislike_count_by_year.loc[\n",
    "            i,\n",
    "        ][2:]\n",
    "        / (video_view_count_by_year.loc[i][2:]),\n",
    "        label=video_dislike_count_by_year.loc[i,][\n",
    "            0:1\n",
    "        ][0],\n",
    "    )\n",
    "plt.semilogy()  \n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.xlabel(\"year\")\n",
    "plt.ylabel(\"video dislikes count\")\n",
    "plt.title(\"video dislikes counts per year for each category\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b99f1da",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a88013",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22d3c6c7",
   "metadata": {},
   "source": [
    "## Question 4: What type of titles attract more attention?\n",
    "Here, we want to do an initial analysis on the titles by analyzing the positive/negative tones and personal pronouns used in them, and how does it change from category to category. For Milestone 3, we want to analyse the changing patterns of titles for the three categories we want to focus on.\n",
    "\n",
    "### Section 1: Number of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6438c43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words_simple(x):\n",
    "    return len(x.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed1167c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all rows with no category label\n",
    "titles_metadata.categories.replace(\"\", np.nan, inplace=True)\n",
    "titles_metadata.dropna(subset=[\"categories\"], inplace=True)\n",
    "\n",
    "titles_metadata['title'] = titles_metadata['title'].apply(lambda x : x.lower())\n",
    "titles_metadata['numwords'] = titles_metadata['title'].apply(lambda text : count_words_simple(text.strip()))\n",
    "titles_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144f9584",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "sns.boxplot(x=\"categories\", y=\"numwords\", data=titles_metadata, showfliers=False)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "ax.set_ylabel(\"number of words in title\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9369fe8",
   "metadata": {},
   "source": [
    "This graph indicates that the title lengths for videos across different categories are not significantly different from each other. That being said, there are some variations, such as that videos under Comedy seem to have less number of words, whereas videos under Entertainment, Gaming, Sports and News & Politics seems to have more words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62574148",
   "metadata": {},
   "source": [
    "### Section 2: Positive and Negative Sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f337965f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the positive words and negative words database\n",
    "POSITIVE_URL = 'https://ptrckprry.com/course/ssd/data/positive-words.txt'\n",
    "NEGATIVE_URL = 'https://ptrckprry.com/course/ssd/data/negative-words.txt'\n",
    "\n",
    "def get_words(URL):\n",
    "    r = requests.get(URL)\n",
    "    data = r.text\n",
    "    words = []\n",
    "    for line in data.split('\\n'):\n",
    "        if ';' not in line and len(line) != 0:\n",
    "            words.append(line)\n",
    "    return words\n",
    "\n",
    "positive_words = get_words(POSITIVE_URL)\n",
    "negative_words = get_words(NEGATIVE_URL)\n",
    "\n",
    "# compare the words in the headline with the words in the list of pos and neg words otherwise it is too expansive \n",
    "def get_columns_pos_neg(list_words, df, colname):\n",
    "    new_column = []\n",
    "    for row in df[colname]:\n",
    "        # get all the words in the headline without ponctuation to be ready to be compared with the neg and pos words  \n",
    "        row_words = re.sub(r'[^\\w\\s]', '', row).split(' ')\n",
    "        if any(word in list_words for word in row_words):\n",
    "            new_column.append(1)\n",
    "        else :\n",
    "            new_column.append(0)      \n",
    "    return new_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a7847e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will first create a copy of titles_metadata with 200000 samples randomly chosen, as running the entire dataset\n",
    "# would take too much time\n",
    "titles_metadata_sample = titles_metadata.iloc[\n",
    "    np.random.choice(np.arange(titles_metadata.shape[0]), 200000), ].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d45324e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add positive and negative score for each title\n",
    "titles_metadata_sample['positive'] = get_columns_pos_neg(positive_words, titles_metadata_sample, 'title')\n",
    "titles_metadata_sample['negative'] = get_columns_pos_neg(negative_words, titles_metadata_sample, 'title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cd51e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count among those video titles containing positive or negative words from our database,\n",
    "# how is the share between positive and negative titles\n",
    "pos_neg_ratio = titles_metadata_sample.groupby(\"categories\").sum()\n",
    "pos_neg_ratio.drop('numwords', inplace=True, axis=1)\n",
    "pos_neg_ratio = pos_neg_ratio/(np.column_stack(pos_neg_ratio.positive + pos_neg_ratio.negative).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee44c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "barWidth = 0.85\n",
    "categories = pos_neg_ratio.index.values.tolist()\n",
    "r = np.arange(len(categories))\n",
    "# Create red Bars\n",
    "plt.bar(r, pos_neg_ratio['negative'], bottom=[i for i in pos_neg_ratio['positive']], color='#F15C6C', \n",
    "        edgecolor='white', width=barWidth, label = \"negative\")\n",
    "# Create green Bars\n",
    "plt.bar(r, pos_neg_ratio['positive'], color='#69BF97', edgecolor='white', width=barWidth, label = \"positive\")\n",
    "\n",
    "# Custom x axis\n",
    "plt.xticks(r, categories)\n",
    "plt.xlabel(\"Categories\")\n",
    "plt.ylabel(\"Share of Videos\")\n",
    "plt.ylim(0,1)\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1,1), ncol=1)\n",
    "plt.xticks(rotation=90)\n",
    "# Show graphic\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603f4963",
   "metadata": {},
   "source": [
    "Here, we can see that in Comedy, Gaming and News & Politics, there more more negative video titles, Autos & Vehicles, Entertainment and Filmd & Amination have more or less the same share, whereas the rest have more positive video titles than negative ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85de4ff5",
   "metadata": {},
   "source": [
    "### Section 3: Personal Pronouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1162eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (this section of code is already provided)\n",
    "feature_wordsets = dict([\n",
    "    # https://en.wikipedia.org/wiki/English_personal_pronouns\n",
    "    ('first_person_singular', ['i', 'me', 'my', 'mine', 'myself',\n",
    "                               \"i'd\", \"i'll\", \"i'm\", \"i've\", 'id', 'im', 'ive']),\n",
    "    ('first_person_plural', ['we', 'us', 'our', 'ours', 'ourselves',\n",
    "                              \"we'd\", \"we'll\", \"we're\", \"we've\",]),\n",
    "    ('second_person', ['you','your','yours','yourself',\n",
    "                              \"ya\", \"you'd\", \"you'll\", \"you're\", \"you've\", 'youll', 'youre', 'youve', \n",
    "                              'yourselves']),\n",
    "    ('third_person_singular', ['he','him','his','himself',\n",
    "                               \"he'd\", \"he's\", 'hes',\n",
    "                               'she','her','hers','herself', \n",
    "                               \"she'll\", \"she's\", 'shes',\n",
    "                               'it','its','itself',\n",
    "                               'themself']),\n",
    "    ('third_person_plural', ['they','them','their','theirs','themselves',\n",
    "                              \"they'd\", \"they'll\", \"they've\", 'theyll', 'theyve'])\n",
    "])\n",
    "\n",
    "(feature_wordsets.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4624af10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_columns_pronouns(feature_wordsets, df, colname):\n",
    "    dict_pronoun_list = dict([\n",
    "        ('first_person_singular', []),\n",
    "        ('first_person_plural', []),\n",
    "        ('second_person', []),\n",
    "        ('third_person_singular', []),\n",
    "        ('third_person_plural', []),\n",
    "    ])\n",
    "    for headline in df[colname]:\n",
    "        for key in feature_wordsets.keys():\n",
    "            # if a word corresponding to a pronoun is present in the headline, \n",
    "            #then add 1 to this pronoun list (column) otherwise add 0 \n",
    "            if any(re.search(r'\\b' + pronoun + r'\\b', headline) for pronoun in feature_wordsets[key]):\n",
    "                dict_pronoun_list[key].append(1)\n",
    "            else :\n",
    "                dict_pronoun_list[key].append(0)\n",
    "    return dict_pronoun_list\n",
    "\n",
    "dict_pronoun_list = get_new_columns_pronouns(feature_wordsets, titles_metadata_sample, 'title')\n",
    "\n",
    "# create the new columns in our dataframe\n",
    "for col in dict_pronoun_list.keys():\n",
    "    titles_metadata_sample[col] = dict_pronoun_list[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10483d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count among those video titles containing personal pronouns from our database,\n",
    "# how is the share between each personal pronoun group\n",
    "per_pro_ratio = titles_metadata_sample.groupby(\"categories\").sum()\n",
    "per_pro_ratio.drop(['numwords','positive', 'negative'], inplace=True, axis=1)\n",
    "per_pro_ratio = per_pro_ratio/(np.column_stack(per_pro_ratio.first_person_singular + \n",
    "                                               per_pro_ratio.first_person_plural +\n",
    "                                               per_pro_ratio.second_person + \n",
    "                                               per_pro_ratio.third_person_singular + \n",
    "                                               per_pro_ratio.third_person_plural).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f723cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "barWidth = 0.85\n",
    "categories = per_pro_ratio.index.values.tolist()\n",
    "r = np.arange(len(categories))\n",
    "\n",
    "plt.bar(r, per_pro_ratio['third_person_plural'], \n",
    "        bottom=[i+j+k+l for i,j,k,l in zip(per_pro_ratio['first_person_singular'], per_pro_ratio['first_person_plural'], \n",
    "                                           per_pro_ratio['second_person'], per_pro_ratio['third_person_singular'])], \n",
    "        color='#8C68AB', edgecolor='white', width=barWidth, label = \"third_person_plural\")\n",
    "\n",
    "plt.bar(r, per_pro_ratio['third_person_singular'], \n",
    "        bottom=[i+j+k for i,j,k in zip(per_pro_ratio['first_person_singular'], \n",
    "                                       per_pro_ratio['first_person_plural'], per_pro_ratio['second_person'])], \n",
    "        color='#E68A99', edgecolor='white', width=barWidth, label = \"third_person_singular\")\n",
    "\n",
    "plt.bar(r, per_pro_ratio['second_person'], \n",
    "        bottom=[i+j for i,j in zip(per_pro_ratio['first_person_singular'], per_pro_ratio['first_person_plural'])], \n",
    "        color='#C1CF94', edgecolor='white', width=barWidth, label = \"second_person\")\n",
    "\n",
    "plt.bar(r, per_pro_ratio['first_person_plural'], \n",
    "        bottom=[i for i in per_pro_ratio['first_person_singular']], \n",
    "        color='#F5E3C1', edgecolor='white', width=barWidth, label = \"first_person_plural\")\n",
    "\n",
    "plt.bar(r, per_pro_ratio['first_person_singular'], \n",
    "        color='#B6B6B6', edgecolor='white', width=barWidth, label = \"first_person_singular\")\n",
    "\n",
    "# Custom x axis\n",
    "plt.xticks(r, categories)\n",
    "plt.xlabel(\"Categories\")\n",
    "plt.ylabel(\"Share of Videos\")\n",
    "plt.ylim(0,1)\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1,1), ncol=1)\n",
    "plt.xticks(rotation=90)\n",
    "# Show graphic\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49841c9c",
   "metadata": {},
   "source": [
    "This shows that the use of personal pronouns varies significantly between different categories. For example, we would expect News & Politics to use less first personal pronouns and more third personal pronouns, since the subjects are often inpersonal and general, whereas for Travel & Events, and People & Blogs, we would expect the video titles to use more first personal pronouns, since the videos are often personal. Both expectations are reflected on the plotting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ee79b8",
   "metadata": {},
   "source": [
    "# Part 2: Further Analysis For Milestone 3\n",
    "\n",
    "In this section, we will focus on three specific categories and determine what are the factors that could lead to more subscriptions. As a reminder, our job in the project is to better inform our young 'brother' who would like to become an YouTuber. Therefore, we will focus on categories that is achievable by just one person, aka, eliminating categories such as Entertainment, News & Politics, Film & Animation, Movies and Shows. Our young 'brother' is not particularly talented in Music, Handcraft, so we will also eliminate Howto & Style, and Music. Since he is still in High School, he is not yet able to explain explain science or teach others, we will also exclude Science & Technology, and Education. From previous graphs, we would recommend him to consider XX, XX and XX.\n",
    "\n",
    "## Question 1: How does the video upload frequency, time of the week, and video length affect the subscription rate of the channels?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8cedb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f180a346",
   "metadata": {},
   "source": [
    "## Question 2: How does the language used in titles affect subscription number?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6691426",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5894abc1",
   "metadata": {},
   "source": [
    "## Question 3:  Can we predict the channel's success based on channel information, including average video length, upload frequency, usual time of uploads, categories of videos uploaded, positive/negative sentiments of the title, usual way of addressing the viewers, the number of words in the title, and the number of tags used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb350ea8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d89b4e0",
   "metadata": {},
   "source": [
    "## Question 4: "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e2552cbddfdf66195580a0cc7030164c04fc13f4bfb78773728a78bbf4f04323"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
