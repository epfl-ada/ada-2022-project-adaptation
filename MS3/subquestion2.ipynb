{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets implement the sub question 2, the goal is to find a relation btw the number of views and the titles (length, sentiment, casefold, etc...). For that an observational studies would be highly recommended to compare what is comparable. For that we will keep the channel id to see the number of subs of the channel and compare pairwise similar nb of subs. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "import statsmodels.formula.api as smf \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_metadatas = pd.read_feather(\"../data/yt_metadata_title_filter_cat_sample.feather\")\n",
    "df_time_series = pd.read_csv(\n",
    "    \"../data/df_timeseries_en.tsv.gz\", compression=\"infer\", sep=\"\\t\"\n",
    ")\n",
    "video_metadatas = video_metadatas.rename({\"index\": \"id\"}, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_metadatas.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_series.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to improve the hw1 method a bit because we want to make sure that titles with a lot of spaces\n",
    "# don't have too many words and if there is a typo (e.g \"Welcome,in my video\" should be counted as 4 words and not 3)\n",
    "def count_words(x: str):\n",
    "    new_x = x.replace(\",\", \" \")\n",
    "    # change anything that isn’t an alphanumeric character or whitespace, and replaces it with a space\n",
    "    new_x = re.sub(r\"[^\\w\\s]\", \" \", new_x)\n",
    "    # Change many consecutive spaces into a single space\n",
    "    new_x = re.sub(\" +\", \" \", new_x)\n",
    "    # delete begin/end spaces\n",
    "    new_x = new_x.strip()\n",
    "    return len(new_x.split(\" \"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(count_words(\"Salut     je suis la\"))\n",
    "print(count_words(\"Salut,je suis la\"))\n",
    "print(count_words(\"#FuckCancer | I'VE GOT SOME GREAT NEWS!\"))\n",
    "print(count_words(\"DISNEY CHRISTMAS VLOG! || Zak Longo\"))\n",
    "print(count_words(\"Sims 4 - SHOOTING SIMS WITH A GUN - The Sims 4\"))\n",
    "print(count_words(\"###ADA#ada##\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_metadatas[\"nb_words\"] = video_metadatas.title.apply(\n",
    "    lambda title: count_words(title)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_freq_capital_words(sentence: str):\n",
    "    new_x = sentence.replace(\",\", \" \")\n",
    "    # change anything that isn’t an alphanumeric character or whitespace, and replaces it with a space\n",
    "    new_x = re.sub(r\"[^\\w\\s]\", \" \", new_x)\n",
    "    # Change many consecutive spaces into a single space\n",
    "    new_x = re.sub(\" +\", \" \", new_x)\n",
    "    # delete begin/end spaces\n",
    "    new_x = new_x.strip().split(\" \")\n",
    "    nb_capital_words = 0\n",
    "    for word in new_x:\n",
    "        if word.isupper():\n",
    "            nb_capital_words += 1\n",
    "    return nb_capital_words / len(new_x)\n",
    "\n",
    "\n",
    "print(get_freq_capital_words(\"Sims 4 - SHOOTING SIMS WITH A GUN - The Sims 4\"))\n",
    "print(get_freq_capital_words(\"###ADA###salut|||test&SALUT\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_metadatas[\"freq_capitalize_words\"] = video_metadatas.title.apply(\n",
    "    lambda title: get_freq_capital_words(title)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze the impact of the upper word in the titles.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distrib of the freq capitalize words.\n",
    "# process for the plot\n",
    "freq_capit_words = round(video_metadatas.freq_capitalize_words, 1)\n",
    "values_counts = freq_capit_words.value_counts().sort_index()\n",
    "values_counts.plot(kind=\"bar\")\n",
    "plt.xlabel(\"frequencies of upper word\")\n",
    "plt.ylabel(\"nb of titles\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_metadatas[\"view_count_log\"] = np.log(video_metadatas.view_count, where=video_metadatas.view_count != 0)\n",
    "mod = smf.ols(formula=\"view_count_log ~ nb_words + freq_capitalize_words\", data=video_metadatas)\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First results, it seems that the upper words seem to impact the number of views for videos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map channels with same nb of followers, but videos with 1 in freq and 0 on the other side and compare the nb of views. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_series.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take df with only 1 and 0 in frequency \n",
    "video_metadatas.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_freq_df = video_metadatas[\n",
    "    (video_metadatas.freq_capitalize_words == 0)\n",
    "    | (video_metadatas.freq_capitalize_words == 1)\n",
    "]\n",
    "binary_freq_df[\"upload_date\"] = pd.to_datetime(binary_freq_df[\"upload_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_freq_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_upper_word_df = binary_freq_df[binary_freq_df[\"freq_capitalize_words\"] == 0]\n",
    "full_upper_word_df = binary_freq_df[binary_freq_df[\"freq_capitalize_words\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "already_matched = {}\n",
    "df_list = []\n",
    "# match same year videos, same category and equal nb of words\n",
    "i = 0\n",
    "shuffle_full_upper_word_df = full_upper_word_df.sample(frac=1, random_state=1)\n",
    "shuffle_no_upper_word_df = no_upper_word_df.sample(frac=1, random_state=1)\n",
    "\n",
    "for _, full_upper_row in shuffle_full_upper_word_df.iterrows():\n",
    "    if i == 100:\n",
    "        print(\"We have 100 pairs\")\n",
    "        break\n",
    "    for _, no_upper_row in shuffle_no_upper_word_df.iterrows(): \n",
    "        if (\n",
    "            (full_upper_row.categories == no_upper_row.categories)\n",
    "            and (full_upper_row.nb_words == no_upper_row.nb_words)\n",
    "            and (full_upper_row.upload_date.year == no_upper_row.upload_date.year)\n",
    "            # and (no_upper_row.id not in already_matched.values())\n",
    "        ):\n",
    "            already_matched[full_upper_row.id] = no_upper_row.id\n",
    "            df_list.append(full_upper_row)\n",
    "            df_list.append(no_upper_row)\n",
    "            i += 1\n",
    "            print(\"{}th match \".format(i))\n",
    "            shuffle_no_upper_word_df.drop(shuffle_no_upper_word_df[shuffle_no_upper_word_df.id == no_upper_row.id].index, inplace=True)\n",
    "            # print(shuffle_no_upper_word_df.shape)\n",
    "            break\n",
    "\n",
    "\n",
    "matched_df = pd.DataFrame(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = smf.ols(formula=\"view_count_log ~ freq_capitalize_words\", data=matched_df)\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "e2552cbddfdf66195580a0cc7030164c04fc13f4bfb78773728a78bbf4f04323"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
