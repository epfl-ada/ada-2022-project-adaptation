{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.font_manager as font_manager\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib as mpl\n",
    "import matplotlib.ticker as mtick\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "params = {\n",
    "    \"axes.titlesize\" : 14,\n",
    "    'axes.labelsize': 12,\n",
    "    'font.size': 12,\n",
    "    'legend.fontsize': 12,\n",
    "    'xtick.labelsize': 12,\n",
    "    'ytick.labelsize': 12,\n",
    "    'text.usetex': False\n",
    "}\n",
    "\n",
    "mpl.rcParams.update(params)\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_series = pd.read_csv(\"./data/df_timeseries_en.tsv.gz\", compression=\"infer\", sep=\"\\t\")\n",
    "df_channels = pd.read_csv(\"./data/df_channels_en.tsv.gz\", compression=\"infer\", sep=\"\\t\")\n",
    "df_time_series[\"datetime\"] = pd.to_datetime(df_time_series[\"datetime\"])\n",
    "df_channels[\"join_date\"] = pd.to_datetime(df_channels[\"join_date\"])\n",
    "video_metadatas = pd.read_feather(\"./data/yt_metadata_helper.feather\", columns=[\"duration\", \"like_count\", \"view_count\", \"channel_id\"])\n",
    "video_metadatas[\"dummmy\"] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check length of videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An idea would be to use cut to match length of videos into discrete intervals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_durations = pd.cut(video_metadatas['duration'], bins=100)\n",
    "print(type(bucket_durations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check frequency of videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How long to reach 100K subscribers for ex "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Could be interesting to take all the videos with 10K, 20K, 30K, ... and see the evolution to reach 100K for example. And compare different evolution : from 50K to 100K or from 500K to 600K, etc.. which one is the fastest, easiest ?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    4769814\n",
      "True      463833\n",
      "Name: channel, dtype: int64\n",
      "We have 463833 channels that begins with 10K and reach at least 100K\n"
     ]
    }
   ],
   "source": [
    "under_10K = df_time_series[df_time_series['subs'] < 10_000]['channel']\n",
    "more_10K = df_time_series[df_time_series['subs'] > 100_000]['channel']\n",
    "print(under_10K.isin(more_10K).value_counts())\n",
    "print('We have {} channels that begins with 10K and reach at least 100K'.format(under_10K.isin(more_10K).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good new, we have a lot of data to analyze!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_metadatas.sample(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_metadatas['duration'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_time_series['category'].unique())\n",
    "print(len(df_time_series['category']))\n",
    "df_time_series.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_channels['category_cc'].unique())\n",
    "print(len(df_channels['category_cc']))\n",
    "df_channels.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the number of channels created every year \n",
    "channel_year = df_channels['join_date'].apply(lambda d: d.to_pydatetime().year)\n",
    "# channel_year.value_counts().sort_values().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ranked_channels = df_channels[df_channels.subscriber_rank_sb < 100]\n",
    "top_ranked_channels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = top_ranked_channels[\"join_date\"].apply(lambda d: d.to_pydatetime().year)\n",
    "np.mean(date, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oldest_video = df_channels['join_date'].apply(lambda d: d.to_pydatetime().year)\n",
    "oldest_video.nsmallest(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oldest_from_series = df_time_series['datetime'].apply(lambda d: d.to_pydatetime().year)\n",
    "oldest_from_series.nsmallest(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_with_largest_subscribers = df_channels.nlargest(53, 'subscribers_cc')\n",
    "channels_with_largest_subscribers.sample(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_series.sample(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_series[df_time_series['channel'] == 'UC-lHJZR3Gqxm24_Vd_AJ5Yw'].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('ada')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e2552cbddfdf66195580a0cc7030164c04fc13f4bfb78773728a78bbf4f04323"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
