{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nadal\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.font_manager as font_manager\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib as mpl\n",
    "import matplotlib.ticker as mtick\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "from scipy.stats import bootstrap\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "params = {\n",
    "    \"axes.titlesize\": 14,\n",
    "    \"axes.labelsize\": 12,\n",
    "    \"font.size\": 12,\n",
    "    \"legend.fontsize\": 12,\n",
    "    \"xtick.labelsize\": 12,\n",
    "    \"ytick.labelsize\": 12,\n",
    "    \"text.usetex\": False,\n",
    "}\n",
    "\n",
    "mpl.rcParams.update(params)\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_series = pd.read_csv(\n",
    "    \"./data/df_timeseries_en.tsv.gz\", compression=\"infer\", sep=\"\\t\"\n",
    ")\n",
    "df_time_series[\"datetime\"] = pd.to_datetime(df_time_series[\"datetime\"])\n",
    "\n",
    "df_channels = pd.read_csv(\"./data/df_channels_en.tsv.gz\", compression=\"infer\", sep=\"\\t\")\n",
    "df_channels[\"join_date\"] = pd.to_datetime(df_channels[\"join_date\"])\n",
    "video_metadatas = pd.read_feather(\n",
    "    \"./data/yt_metadata_helper.feather\",\n",
    "    columns=[\n",
    "        \"categories\",\n",
    "        \"upload_date\",\n",
    "        \"duration\",\n",
    "        \"like_count\",\n",
    "        \"view_count\",\n",
    "        \"channel_id\",\n",
    "    ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round the subs value, easier to consider 1 sub as a person and not half of a person...\n",
    "df_time_series.subs = df_time_series.subs.round(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_series.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_channels.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_metadatas.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check length of videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An idea would be to use cut to match length of videos into discrete intervals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_metadatas.duration.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To make it easier to grasp the length of videos, we will convert the lengths to minutes at first...\n",
    "video_metadatas[\"duration_min\"] = video_metadatas[\"duration\"] / 60\n",
    "video_metadatas.duration_min.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(video_metadatas[\"duration_min\"], showfliers=False, vert=False)\n",
    "plt.title(\"Duration of Videos in Minutes\")\n",
    "plt.xlabel(\"Duration in Minutes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_min_cumul = plt.hist(\n",
    "    video_metadatas.duration_min, bins=100, log=True, cumulative=-1, histtype=\"step\"\n",
    ")\n",
    "plt.title(\"Histogram of Duration for YouTube Videos (cumulative)\")\n",
    "plt.ylabel(\"# of Videos (in log scale)\")\n",
    "plt.xlabel(\"Duration in Minutes\")\n",
    "plt.xticks(rotation=30, ha=\"right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.loglog(duration_min_cumul[1][1:], duration_min_cumul[0])\n",
    "plt.title(\"Histogram of Duration for YouTube Videos (cumulative)\")\n",
    "plt.ylabel(\"# of Videos (in log scale)\")\n",
    "plt.xlabel(\"Duration\")\n",
    "plt.xticks(rotation=30, ha=\"right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# long to compute\n",
    "\n",
    "# bucket_durations = pd.cut(video_metadatas['duration'], bins=100)\n",
    "# print(type(bucket_durations))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check frequency of videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_count = (\n",
    "    video_metadatas.groupby(pd.Grouper(key=\"upload_date\", freq=\"W\")).count().channel_id\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(video_count, color=\"#7570b3\", ls=\"--\", label=\"\\% videos uploaded\")\n",
    "plt.yscale(\"log\")\n",
    "plt.ylabel(\"Number of Videos\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.title(\"Number of videos updated each week\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will determine how many videos are uploaded to YouTube by each channel by year\n",
    "video_metadatas[\"yearkNumber\"] = video_metadatas[\"upload_date\"].dt.year\n",
    "vd_cnt_by_id_yr = (\n",
    "    video_metadatas.groupby([\"channel_id\", \"yearkNumber\"])\n",
    "    .count().categories.unstack().reset_index()\n",
    ")\n",
    "vd_cnt_by_id_yr.columns.name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we now remove the channels that uploaded less than 12 videos throughout the study period\n",
    "vd_cnt_by_id_yr_filtered = vd_cnt_by_id_yr[vd_cnt_by_id_yr.sum(axis=1)>12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vd_cnt_by_id_yr_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vd_cnt_by_id_yr_filtered_summary = vd_cnt_by_id_yr_filtered.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vd_cnt_by_id_yr_filtered_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.fill_between(x=list(vd_cnt_by_id_yr_filtered_summary.columns.values),\n",
    "                y1=list(vd_cnt_by_id_yr_filtered_summary.loc[\"25%\",:]),\n",
    "                y2=list(vd_cnt_by_id_yr_filtered_summary.loc[\"75%\",:]), \n",
    "                 alpha = 0.5, color = 'gray')\n",
    "plt.plot(vd_cnt_by_id_yr_filtered_summary.loc[\"50%\",:], color = 'black')\n",
    "\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Yearly Upload Frequency')\n",
    "plt.title('The quantiles of yearly video upload frequency')\n",
    "# here we choose quantiles, since mean would be significantly affected by the extremely high yearly upload rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How long to reach 1M subscribers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Could be interesting to take all the videos with 10K, 20K, 30K, ... and see the evolution to reach 100K for example. And compare different evolution : from 50K to 100K or from 500K to 600K, etc.. which one is the fastest, easiest ?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_channel_ascension(start_subs, end_subs):\n",
    "    \"\"\"finds the channels in the time series that have less than the start_subs and more than end_subs.\n",
    "    It means that it begins with less than start_subs and have now at least end_subs\n",
    "\n",
    "    Args:\n",
    "        start_subs (float): low_threshold\n",
    "        end_subs (float): high_threshold\n",
    "\n",
    "    Returns:\n",
    "        dataframe containing all the channels with evolution from starts_subs to end_subs\n",
    "    \"\"\"\n",
    "    under_start_subs = df_time_series[df_time_series[\"subs\"] < start_subs]\n",
    "    more_end_subs = df_time_series[df_time_series[\"subs\"] > end_subs]\n",
    "    channel_start_to_end = df_time_series[\n",
    "        df_time_series.channel.isin(under_start_subs.channel)\n",
    "        & df_time_series.channel.isin(more_end_subs.channel)\n",
    "    ]\n",
    "    return channel_start_to_end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_time_to_reach_X_subs(df, lower_bound, upper_bound):\n",
    "    time_to_reach_X_subs = df.groupby(\"channel\").apply(\n",
    "        lambda group: pd.Series(\n",
    "            {\n",
    "                \"from_zero_to_hero_duration\": group[group.subs > upper_bound][\n",
    "                    \"datetime\"\n",
    "                ].iloc[0]\n",
    "                - group[group.subs < lower_bound][\"datetime\"].iloc[-1]\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "    return time_to_reach_X_subs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_10K_to_1M = get_df_channel_ascension(10_000, 1_000_000)\n",
    "print(\n",
    "    \"We have {} channels that begins with 10K subs and reach at least 1M\".format(\n",
    "        channel_10K_to_1M.channel.nunique()\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_channel = channel_10K_to_1M.iloc[0]\n",
    "test = channel_10K_to_1M[channel_10K_to_1M[\"channel\"] == first_channel.channel]\n",
    "# test = test[(test['datetime'] > np.datetime64('2018-07-20')) & (test['datetime'] < np.datetime64('2019-01-20'))]\n",
    "test.plot(x=\"datetime\", y=\"subs\")\n",
    "print(\"There are {} weeks for this channel\".format(test.shape[0]))\n",
    "print(\n",
    "    \"We should have approximately the same value : \\n{} and {}\".format(\n",
    "        7 * test.shape[0], test.iloc[-1].datetime - test.iloc[0].datetime\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the time it takes to go from less than 10K to 1M\n",
    "time_to_reach_1M = get_mean_time_to_reach_X_subs(channel_10K_to_1M, 10_000, 1_000_000)\n",
    "time_to_reach_1M.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"In average YTbers take {} days to reach 1M of subscribers\".format(\n",
    "        time_to_reach_1M[\"from_zero_to_hero_duration\"].mean().days\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be nice to bootstrap this result to see with interval of confidence the time taken by Youtuber to reach 1M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = time_to_reach_1M[\"from_zero_to_hero_duration\"].apply(\n",
    "    lambda delta_time: delta_time.days\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng()\n",
    "conf_interval_reach_1M = bootstrap(\n",
    "    (data,),\n",
    "    np.mean,\n",
    "    confidence_level=0.95,\n",
    "    random_state=rng,\n",
    ").confidence_interval\n",
    "conf_interval_reach_1M\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"The 95% interval of confidence, the time taken to reach 1M (from 10K) is [{}, {}]\".format(\n",
    "        conf_interval_reach_1M.low, conf_interval_reach_1M.high\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the number of views (maybe after we could add likes, dislike) given a certain categories and date of videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this task lets analyze and after ploting and getting some intuition, use logistic regression to 'predict' the nb of views given category and date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_metadatas.head()\n",
    "video_metadatas.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the rows with empty categories\n",
    "videos_with_cat = video_metadatas\n",
    "videos_with_cat.categories.replace(\"\", np.nan, inplace=True)\n",
    "videos_with_cat.dropna(subset=[\"categories\"], inplace=True)\n",
    "videos_with_cat.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_cat = pd.get_dummies(videos_with_cat.categories)\n",
    "video_metadatas_encoded = videos_with_cat.join(encoded_cat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_metadatas_encoded[\"year\"] = video_metadatas_encoded[\"upload_date\"].dt.year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_metadatas_encoded.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_metadatas_encoded.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wenxiu Comments: we probably should change the naming of columns - at least on my laptop the ones with & are not identified\n",
    "model = smf.ols(\n",
    "    formula='view_count ~ year + C(Autos & Vehicles) + C(Comedy) + C(Education) + C(Entertainment) + C(Film & Animation) + \\\n",
    "                C(Gaming) + C(Movies) + C(Music) + C(News & Politics) + C(Nonprofits & Activism) + \\\n",
    "                C(People & Blogs) + C(Pets & Animals) + C(Science & Technology) + C(Shows) + C(Sports) + C(Travel & Events)',\n",
    "    data=video_metadatas_encoded\n",
    ")\n",
    "\n",
    "res = model.fit()\n",
    "print(res.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ranked_channels = df_channels[df_channels.subscriber_rank_sb < 100]\n",
    "top_ranked_channels.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = top_ranked_channels[\"join_date\"].apply(lambda d: d.to_pydatetime().year)\n",
    "np.mean(date, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oldest_video = df_channels[\"join_date\"].apply(lambda d: d.to_pydatetime().year)\n",
    "oldest_video.nsmallest(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_with_largest_subscribers = df_channels.nlargest(53, \"subscribers_cc\")\n",
    "channels_with_largest_subscribers.sample(7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most common tags per category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Paul) I will start this part when I find how to create videos metadata dataset with tags (& title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = pd.read_feather(\n",
    "    \"./data/yt_metadata_tags_helper.feather\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categories</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>lego city,lego police,lego city police,lego ci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>Lego superheroes,lego hulk,hulk smash,lego mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>lego city,lego police,lego city police,lego fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>Lego harry potter,new harry potter,harry potte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>lego city,lego police,lego city police,lego fi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         categories                                               tags\n",
       "0  Film & Animation  lego city,lego police,lego city police,lego ci...\n",
       "1  Film & Animation  Lego superheroes,lego hulk,hulk smash,lego mar...\n",
       "2  Film & Animation  lego city,lego police,lego city police,lego fi...\n",
       "3  Film & Animation  Lego harry potter,new harry potter,harry potte...\n",
       "4  Film & Animation  lego city,lego police,lego city police,lego fi..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags.shape\n",
    "tags.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e22c46614c12b51e434b1987d6d67df3c07a865fc0708b93ab6cef9973e51d54"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
