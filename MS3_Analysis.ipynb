{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2af5202-cd4d-4fe2-9e7e-48869ec70229",
   "metadata": {},
   "source": [
    "# Part 0: Initialising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b347be5c-381b-4203-a676-ae35909a42cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing\n",
    "import matplotlib.font_manager as font_manager\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib as mpl\n",
    "import matplotlib.ticker as mtick\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "from scipy.stats import bootstrap\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import requests\n",
    "\n",
    "params = {\n",
    "    \"axes.titlesize\": 14,\n",
    "    \"axes.labelsize\": 12,\n",
    "    \"font.size\": 12,\n",
    "    \"legend.fontsize\": 12,\n",
    "    \"xtick.labelsize\": 12,\n",
    "    \"ytick.labelsize\": 12,\n",
    "    \"text.usetex\": False,\n",
    "}\n",
    "\n",
    "NUM_COLORS = 15\n",
    "cm = plt.get_cmap('nipy_spectral')\n",
    "\n",
    "mpl.rcParams.update(params)\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4e5555-b4fc-4cd9-acea-f54ff5aef1ad",
   "metadata": {},
   "source": [
    "To start with, we import three datasets that are available from YouNiverse:\n",
    "\n",
    "``df_timeseries_en.tsv.gz``  \n",
    "``df_channels_en.tsv.gz``  \n",
    "``yt_metadata_helper.feather``\n",
    "\n",
    "We will filter the channels that have been identified as Gaming, People & Blogs, or Comedy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c93da3e-46e0-4e9b-98dc-c725a9d981fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_series = pd.read_csv(\n",
    "    \"./data/df_timeseries_en.tsv.gz\", compression=\"infer\", sep=\"\\t\"\n",
    ")\n",
    "df_time_series[\"datetime\"] = pd.to_datetime(df_time_series[\"datetime\"])\n",
    "# round the total number of subscribers, it is easier to consider 1 person and instead half of a person...\n",
    "df_time_series.subs = df_time_series.subs.round(0)\n",
    "\n",
    "# filter channels we want\n",
    "df_time_series = df_time_series[df_time_series.category.isin(\n",
    "    ['Gaming', 'People & Blogs', 'Comedy']\n",
    ")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18ad73d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel</th>\n",
       "      <th>category</th>\n",
       "      <th>datetime</th>\n",
       "      <th>views</th>\n",
       "      <th>delta_views</th>\n",
       "      <th>subs</th>\n",
       "      <th>delta_subs</th>\n",
       "      <th>videos</th>\n",
       "      <th>delta_videos</th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>UCxJWPpPED-J24znoKyKZYjg</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>2017-03-06</td>\n",
       "      <td>1607.50</td>\n",
       "      <td>285.50</td>\n",
       "      <td>183.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>UCxJWPpPED-J24znoKyKZYjg</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>2017-03-13</td>\n",
       "      <td>2695.75</td>\n",
       "      <td>1088.25</td>\n",
       "      <td>317.0</td>\n",
       "      <td>134.5</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      channel category   datetime    views  delta_views  \\\n",
       "301  UCxJWPpPED-J24znoKyKZYjg   Comedy 2017-03-06  1607.50       285.50   \n",
       "302  UCxJWPpPED-J24znoKyKZYjg   Comedy 2017-03-13  2695.75      1088.25   \n",
       "\n",
       "      subs  delta_subs  videos  delta_videos  activity  \n",
       "301  183.0         0.0       7             0         2  \n",
       "302  317.0       134.5       8             1         2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_time_series.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aac6cc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_channels = pd.read_csv(\"./data/df_channels_en.tsv.gz\", compression=\"infer\", sep=\"\\t\")\n",
    "df_channels[\"join_date\"] = pd.to_datetime(df_channels[\"join_date\"])\n",
    "\n",
    "# filter channels we want\n",
    "df_channels = df_channels[df_channels.category_cc.isin(\n",
    "    ['Gaming', 'People & Blogs', 'Comedy']\n",
    ")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e9fd32a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_cc</th>\n",
       "      <th>join_date</th>\n",
       "      <th>channel</th>\n",
       "      <th>name_cc</th>\n",
       "      <th>subscribers_cc</th>\n",
       "      <th>videos_cc</th>\n",
       "      <th>subscriber_rank_sb</th>\n",
       "      <th>weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gaming</td>\n",
       "      <td>2010-04-29</td>\n",
       "      <td>UC-lHJZR3Gqxm24_Vd_AJ5Yw</td>\n",
       "      <td>PewDiePie</td>\n",
       "      <td>101000000</td>\n",
       "      <td>3956</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Gaming</td>\n",
       "      <td>2015-04-06</td>\n",
       "      <td>UCEdvpU2pFRCVqU6yIPyTpMQ</td>\n",
       "      <td>Marshmello</td>\n",
       "      <td>39100000</td>\n",
       "      <td>366</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Comedy</td>\n",
       "      <td>2005-11-19</td>\n",
       "      <td>UCY30JRSgfhYXA6i6xX1erWg</td>\n",
       "      <td>Smosh</td>\n",
       "      <td>24800000</td>\n",
       "      <td>1074</td>\n",
       "      <td>85.0</td>\n",
       "      <td>2.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Gaming</td>\n",
       "      <td>2012-05-26</td>\n",
       "      <td>UC7_YxT-KID8kRbqZo7MyscQ</td>\n",
       "      <td>Markiplier</td>\n",
       "      <td>24400000</td>\n",
       "      <td>4484</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2.087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category_cc  join_date                   channel     name_cc  \\\n",
       "0       Gaming 2010-04-29  UC-lHJZR3Gqxm24_Vd_AJ5Yw   PewDiePie   \n",
       "10      Gaming 2015-04-06  UCEdvpU2pFRCVqU6yIPyTpMQ  Marshmello   \n",
       "40      Comedy 2005-11-19  UCY30JRSgfhYXA6i6xX1erWg       Smosh   \n",
       "41      Gaming 2012-05-26  UC7_YxT-KID8kRbqZo7MyscQ  Markiplier   \n",
       "\n",
       "    subscribers_cc  videos_cc  subscriber_rank_sb  weights  \n",
       "0        101000000       3956                 3.0    2.087  \n",
       "10        39100000        366                18.0    2.087  \n",
       "40        24800000       1074                85.0    2.087  \n",
       "41        24400000       4484                86.0    2.087  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_channels.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfb8de83-f104-4db7-a03d-45eedff3600d",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_metadatas = pd.read_feather(\n",
    "    \"./data/yt_metadata_helper.feather\",\n",
    "    columns=[\n",
    "        \"categories\",\n",
    "        \"upload_date\",\n",
    "        \"duration\",\n",
    "        \"like_count\",\n",
    "        \"dislike_count\",\n",
    "        \"view_count\",\n",
    "        \"channel_id\",\n",
    "        \"display_id\"\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1d527e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_metadatas = video_metadatas[\n",
    "    video_metadatas['channel_id'].isin(df_channels.channel)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9146581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categories</th>\n",
       "      <th>upload_date</th>\n",
       "      <th>duration</th>\n",
       "      <th>like_count</th>\n",
       "      <th>dislike_count</th>\n",
       "      <th>view_count</th>\n",
       "      <th>channel_id</th>\n",
       "      <th>display_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>2016-09-28</td>\n",
       "      <td>1159</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1057.0</td>\n",
       "      <td>UCzWrhkg9eK5I8Bm3HfV-unA</td>\n",
       "      <td>SBqSc91Hn9g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>2016-09-28</td>\n",
       "      <td>2681</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12894.0</td>\n",
       "      <td>UCzWrhkg9eK5I8Bm3HfV-unA</td>\n",
       "      <td>UuugEl86ESY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>2016-09-28</td>\n",
       "      <td>1394</td>\n",
       "      <td>1607.0</td>\n",
       "      <td>779.0</td>\n",
       "      <td>1800602.0</td>\n",
       "      <td>UCzWrhkg9eK5I8Bm3HfV-unA</td>\n",
       "      <td>oB4c-yvnbjs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>2016-09-28</td>\n",
       "      <td>5064</td>\n",
       "      <td>227.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>57640.0</td>\n",
       "      <td>UCzWrhkg9eK5I8Bm3HfV-unA</td>\n",
       "      <td>ZaV-gTCMV8E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>2016-09-28</td>\n",
       "      <td>3554</td>\n",
       "      <td>105.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>86368.0</td>\n",
       "      <td>UCzWrhkg9eK5I8Bm3HfV-unA</td>\n",
       "      <td>cGvL7AvMfM0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         categories upload_date  duration  like_count  dislike_count  \\\n",
       "0  Film & Animation  2016-09-28      1159         8.0            1.0   \n",
       "1  Film & Animation  2016-09-28      2681        23.0            1.0   \n",
       "2  Film & Animation  2016-09-28      1394      1607.0          779.0   \n",
       "3  Film & Animation  2016-09-28      5064       227.0           24.0   \n",
       "4  Film & Animation  2016-09-28      3554       105.0           13.0   \n",
       "\n",
       "   view_count                channel_id   display_id  \n",
       "0      1057.0  UCzWrhkg9eK5I8Bm3HfV-unA  SBqSc91Hn9g  \n",
       "1     12894.0  UCzWrhkg9eK5I8Bm3HfV-unA  UuugEl86ESY  \n",
       "2   1800602.0  UCzWrhkg9eK5I8Bm3HfV-unA  oB4c-yvnbjs  \n",
       "3     57640.0  UCzWrhkg9eK5I8Bm3HfV-unA  ZaV-gTCMV8E  \n",
       "4     86368.0  UCzWrhkg9eK5I8Bm3HfV-unA  cGvL7AvMfM0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_metadatas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c191d301",
   "metadata": {},
   "source": [
    "We also import a dataset that is created by us, .......  \n",
    "\n",
    "We will filter the channels that have been identified as Gaming, People & Blogs, or Comedy. Note that this does not necessarily mean that all the videos from those channels are in these categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6dc9dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_metadata = pd.read_feather(\n",
    "    \"./data/yt_metadata_title_helper.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a29d0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_metadata = titles_metadata[\n",
    "    titles_metadata['display_id'].isin(video_metadatas.display_id)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70ecc4d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categories</th>\n",
       "      <th>display_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>SBqSc91Hn9g</td>\n",
       "      <td>Lego City Police Lego Firetruck Cartoons about...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>UuugEl86ESY</td>\n",
       "      <td>Lego Marvel SuperHeroes Lego Hulk Smash Iron-M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>oB4c-yvnbjs</td>\n",
       "      <td>Lego City Police Lego Fireman Cartoons about L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>ZaV-gTCMV8E</td>\n",
       "      <td>Lego Harry Potter Complete Lego New Movie for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>cGvL7AvMfM0</td>\n",
       "      <td>Lego City Police 1 HOUR LONG VIDEO for kids Le...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         categories   display_id  \\\n",
       "0  Film & Animation  SBqSc91Hn9g   \n",
       "1  Film & Animation  UuugEl86ESY   \n",
       "2  Film & Animation  oB4c-yvnbjs   \n",
       "3  Film & Animation  ZaV-gTCMV8E   \n",
       "4  Film & Animation  cGvL7AvMfM0   \n",
       "\n",
       "                                               title  \n",
       "0  Lego City Police Lego Firetruck Cartoons about...  \n",
       "1  Lego Marvel SuperHeroes Lego Hulk Smash Iron-M...  \n",
       "2  Lego City Police Lego Fireman Cartoons about L...  \n",
       "3  Lego Harry Potter Complete Lego New Movie for ...  \n",
       "4  Lego City Police 1 HOUR LONG VIDEO for kids Le...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "333d7f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_metadata = pd.read_feather(\n",
    "    \"./data/yt_metadata_tags_helper.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a07df274",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_metadata = tags_metadata[\n",
    "    tags_metadata['display_id'].isin(tags_metadata.display_id)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99b37b20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categories</th>\n",
       "      <th>display_id</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>SBqSc91Hn9g</td>\n",
       "      <td>lego city,lego police,lego city police,lego ci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>UuugEl86ESY</td>\n",
       "      <td>Lego superheroes,lego hulk,hulk smash,lego mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>oB4c-yvnbjs</td>\n",
       "      <td>lego city,lego police,lego city police,lego fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>ZaV-gTCMV8E</td>\n",
       "      <td>Lego harry potter,new harry potter,harry potte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>cGvL7AvMfM0</td>\n",
       "      <td>lego city,lego police,lego city police,lego fi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         categories   display_id  \\\n",
       "0  Film & Animation  SBqSc91Hn9g   \n",
       "1  Film & Animation  UuugEl86ESY   \n",
       "2  Film & Animation  oB4c-yvnbjs   \n",
       "3  Film & Animation  ZaV-gTCMV8E   \n",
       "4  Film & Animation  cGvL7AvMfM0   \n",
       "\n",
       "                                                tags  \n",
       "0  lego city,lego police,lego city police,lego ci...  \n",
       "1  Lego superheroes,lego hulk,hulk smash,lego mar...  \n",
       "2  lego city,lego police,lego city police,lego fi...  \n",
       "3  Lego harry potter,new harry potter,harry potte...  \n",
       "4  lego city,lego police,lego city police,lego fi...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ee79b8",
   "metadata": {},
   "source": [
    "# Part 2: Further Analysis Milestone 3\n",
    "\n",
    "Given the results in Part 1 of our Analysis, we decided to focus on the categories of Gaming, People & Blogs, Comedy. The reason behind this choice is because we are trying to help our little brother to succeed, and since he is just a single person without a big team behind him it seems more reasonable than e.g. Movies or Film & Entertainment. Therefore, we decided to eliminate Music, How-to & Style, Education, Science & Technology, Entertainment, Film & Entertainment, Movies and Shows. We decided to investigate the three categories mentioned above also because videos uploaded can be addressed to audiences of all three categories.\n",
    "\n",
    "## Key Questions:\n",
    " - Which factors help a YouTuber in Gaming, People & Blogs or Comedy respectively gain more subscribers?\n",
    " - How do sentiments in titles and tags affect views and how do these relationships change over time?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac192b0a",
   "metadata": {},
   "source": [
    "### Sub-Question 1 \n",
    "\n",
    "**Description:** How does the video upload frequency, time of the week, and video length affect the subscription rate of the channels?  \n",
    "**Method:** Model this using a linear regression model.  \n",
    "**Timeline:** By 13/12/2022  \n",
    "**Organization:** Paul  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8cedb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a3edac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f180a346",
   "metadata": {},
   "source": [
    "### Sub-Question 2\n",
    "\n",
    "**Description:** How does the language used in titles affect subscription number?  \n",
    "**Method:** We will classify the sentiments of titles and tags using packages such as NLTK and try to see if this factor affects subscription number of the channels using relevant skills we learned in observational studies.  \n",
    "**Timeline:** By 15/12/2022  \n",
    "**Organization:** Wenxiu  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6691426",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NLP libraries\n",
    "import spacy, nltk, gensim, sklearn\n",
    "\n",
    "#Vader\n",
    "import vaderSentiment\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "061c2bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the Spacy analyzer in English\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b9b69928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "\n",
    "analyzer.polarity_scores(titles_metadata.title[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ae09e5e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m positive_sent \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#iterate through the sentences, get polarity scores, choose a value\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m [positive_sent\u001b[38;5;241m.\u001b[39mappend(analyzer\u001b[38;5;241m.\u001b[39mpolarity_scores(title)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpos\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m title \u001b[38;5;129;01min\u001b[39;00m titles_metadata\u001b[38;5;241m.\u001b[39mtitle]\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mhist(positive_sent,bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m)\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlim([\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m])\n",
      "Input \u001b[1;32mIn [29]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m positive_sent \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#iterate through the sentences, get polarity scores, choose a value\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m [positive_sent\u001b[38;5;241m.\u001b[39mappend(\u001b[43manalyzer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolarity_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpos\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m title \u001b[38;5;129;01min\u001b[39;00m titles_metadata\u001b[38;5;241m.\u001b[39mtitle]\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mhist(positive_sent,bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m)\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlim([\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\vaderSentiment\\vaderSentiment.py:254\u001b[0m, in \u001b[0;36mSentimentIntensityAnalyzer.polarity_scores\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    251\u001b[0m         prev_space \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mchr\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    252\u001b[0m text \u001b[38;5;241m=\u001b[39m text_no_emoji\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m--> 254\u001b[0m sentitext \u001b[38;5;241m=\u001b[39m \u001b[43mSentiText\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m sentiments \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    257\u001b[0m words_and_emoticons \u001b[38;5;241m=\u001b[39m sentitext\u001b[38;5;241m.\u001b[39mwords_and_emoticons\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\vaderSentiment\\vaderSentiment.py:165\u001b[0m, in \u001b[0;36mSentiText.__init__\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    163\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(text)\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;241m=\u001b[39m text\n\u001b[1;32m--> 165\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwords_and_emoticons \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_words_and_emoticons\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;66;03m# doesn't separate words from\\\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;66;03m# adjacent punctuation (keeps emoticons & contractions)\u001b[39;00m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_cap_diff \u001b[38;5;241m=\u001b[39m allcap_differential(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwords_and_emoticons)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\vaderSentiment\\vaderSentiment.py:190\u001b[0m, in \u001b[0;36mSentiText._words_and_emoticons\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;124;03mRemoves leading and trailing puncutation\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;124;03mLeaves contractions and most emoticons\u001b[39;00m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;124;03m    Does not preserve punc-plus-letter emoticons (e.g. :D)\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    189\u001b[0m wes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39msplit()\n\u001b[1;32m--> 190\u001b[0m stripped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_strip_punc_if_word\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stripped\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\vaderSentiment\\vaderSentiment.py:179\u001b[0m, in \u001b[0;36mSentiText._strip_punc_if_word\u001b[1;34m(token)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;124;03mRemoves all trailing and leading punctuation\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;124;03mIf the resulting string has two or fewer characters,\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;124;03mthen it was likely an emoticon, so return original string\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;124;03m(ie \":)\" stripped would be \"\", so just return \":)\"\u001b[39;00m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    178\u001b[0m stripped \u001b[38;5;241m=\u001b[39m token\u001b[38;5;241m.\u001b[39mstrip(string\u001b[38;5;241m.\u001b[39mpunctuation)\n\u001b[1;32m--> 179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstripped\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m token\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stripped\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "positive_sent = []\n",
    "#iterate through the sentences, get polarity scores, choose a value\n",
    "[positive_sent.append(analyzer.polarity_scores(title)['pos']) for title in titles_metadata.title]\n",
    "plt.hist(positive_sent,bins=15)\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,8000])\n",
    "plt.xlabel('Positive sentiment')\n",
    "plt.ylabel('Number of sentences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7966564",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_sent = []\n",
    "#iterate through the sentences, get polarity scores, choose a value\n",
    "[negative_sent.append(analyzer.polarity_scores(title)['neg']) for title in titles_metadata.title]\n",
    "plt.hist(negative_sent,bins=15)\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,8000])\n",
    "plt.xlabel('Positive sentiment')\n",
    "plt.ylabel('Number of sentences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b2f0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral_sent = []\n",
    "#iterate through the sentences, get polarity scores, choose a value\n",
    "[neutral_sent.append(analyzer.polarity_scores(title)['neu']) for title in titles_metadata.title]\n",
    "plt.hist(neutral_sent,bins=15)\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,8000])\n",
    "plt.xlabel('Positive sentiment')\n",
    "plt.ylabel('Number of sentences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfa496a",
   "metadata": {},
   "outputs": [],
   "source": [
    "compound_sent = []\n",
    "#iterate through the sentences, get polarity scores, choose a value\n",
    "[compound_sent.append(analyzer.polarity_scores(title)['compound']) for title in titles_metadata.title]\n",
    "plt.hist(compound_sent,bins=15)\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,8000])\n",
    "plt.xlabel('Positive sentiment')\n",
    "plt.ylabel('Number of sentences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65bb5d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d08869",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ea5941",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5894abc1",
   "metadata": {},
   "source": [
    "### Sub-Question 3\n",
    "\n",
    "**Description:** Can we predict the channel's success based on channel information, including average video length, upload frequency, usual time of uploads, categories of videos uploaded, positive/negative sentiments of the title, person pronouns to address the viewers, the number of words in the title, and the number of tags used?  \n",
    "**Method:** We can implement kNN method or Random Forests to train the dataset.  \n",
    "**Timeline:** By 13/12/2022  \n",
    "**Organization:** Dorothee  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb350ea8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57be6ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d89b4e0",
   "metadata": {},
   "source": [
    "### Sub-Question 4\n",
    "**Description:** What are the most common topics in each of the chosen categories?  \n",
    "**Method:** The yt_metadata_en.jsonl.gz dataset will be used to get a list of tags of each video according to its category. It is further split and classified according to the topics that occur most frequently. This way, we get the most used keywords in each video category and therefore the most popular topics.  \n",
    "**Timeline:** By 15/12/2022  \n",
    "**Organization:** Jules  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272014e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4640ed6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2600e95a",
   "metadata": {},
   "source": [
    "### Sub-Question 5\n",
    "**Description:** Does a channel's success increase with a greater variety of categories?\n",
    "**Method:** For this question, we will determine whether the filtered channels use multiple categories in their videos, and if they showed clear shifts from one category to another. Ultimately, we want to use this information and methods such as A/B testing and observational studies to determine whether a greater variety of categories can aid to a channelsâ€™ success.  \n",
    "**Timeline:** By 18/12/2022  \n",
    "**Organization:** Paul  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15721c01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cad8f80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "f8cc0e3d8506d0e0d1503ea89400fd398a038f9e28e3673a3041501c80962045"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
